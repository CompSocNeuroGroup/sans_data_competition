{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Data\n",
    "\n",
    "For this data competition, we will be using the Friday Night Lights dataset from:\n",
    "\n",
    "[Chang, L. J., Jolly, E., Cheong, J. H., Rapuano, K. M., Greenstein, N., Chen, P. H. A., & Manning, J. R. (2021). Endogenous variation in ventromedial prefrontal cortex state dynamics during naturalistic viewing reflects affective experience. *Science Advances, 7(17), eabf7129*.](https://www.science.org/doi/10.1126/sciadv.abf7129)\n",
    "\n",
    "In this dataset, participants (n=35) watched the pilot episode of the NBC television show Friday Night Lights while undergoing fMRI. We are sharing the raw data in the BIDS format. We are also sharing data that has been preprocessed using fMRIPrep version 20.2.1. See ```derivatives/code/fmriprep.sh``` for the script used to run preprocessing. We have also performed denoising on the preprocessed data by running a univariate GLM, which included the following regressors:\n",
    "\n",
    "- Intercept, Linear & Quadratic Trends (3)\n",
    "- Expanded Realignment Parameters (24). Derivatives, quadratics, quadratic derivatives\n",
    "- Spikes based on global outliers greater than 3 SD and also based on average frame differencing\n",
    "- CSF regressor (1)\n",
    "\n",
    "See ```derivatives/code/Denoise_Preprocessed_Data.ipynb``` file for full details of the denoising model. We have included denoised data that is unsmoothed and also has been smoothed with a 6mm FWHM Gaussian kernel. We have included nifti and hdf5 versions of the data. Nifti files can be loaded using any software. HDF5 files are much faster to load if you are using our [nltools](https://nltools.org/) toolbox for your data analyses. Note that subject ```sub-sid000496``` had bad normalization using this preprocessing pipeline, so we have not included this participant in the denoised data. \n",
    "\n",
    "We are also sharing additional data from this paper, which may be used in projects:\n",
    "\n",
    "- Study 1 (n=13) fMRI Data viewing episodes 1 & 2 - Available on [OpenNeuro](https://openneuro.org/datasets/ds003524).\n",
    "\n",
    "- Study 3 (n=20) Face Expression Data - Available on [OSF](https://osf.io/f9gyd/). We are only sharing extracted Action Unit Values. We do not have permission to share raw video data.\n",
    "\n",
    "- Study 4 (n=192) Emotion Ratings - Available on [OSF](https://osf.io/f9gyd/). Rating data was collected on Amazon Mechanical Turk using a custom Flask [web application](https://github.com/cosanlab/moth_app).\n",
    "\n",
    "- Code from the original paper is available on [Github](https://github.com/cosanlab/vmPFC_dynamics)\n",
    "\n",
    "# Downloading Data\n",
    "\n",
    "All of the data is being hosted by [OpenNeuro](https://openneuro.org/datasets/ds003521). The entire dataset is about 202gb and can be downloaded directly from the website and also using the AWS command line interface. See the OpenNeuro [instructions](https://openneuro.org/datasets/ds003521/download) for downloading. However, as most people have limited storage space, we recommend using Datalad to only download the files you want to work with. We have included a brief overview of working with Datalad from the command line and within Python below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLad\n",
    "\n",
    "We encourage participants to download the data using [DataLad](https://www.datalad.org/), which is an open source version control system for data built on top of [git-annex](https://git-annex.branchable.com/). Think of it like git for data. It provides a handy command line interface for downloading data, tracking changes, and sharing it with others.\n",
    "\n",
    "While DataLad offers a number of useful features for working with datasets, there are three in particular that we think make it worth the effort to install for this competition.\n",
    "\n",
    "1) Cloning a DataLad Repository can be completed with a single line of code `datalad install <repository>` and provides the full directory structure in the form of symbolic links. This allows you to explore all of the files in the dataset, without having to download the entire dataset at once.\n",
    "\n",
    "2) Specific files can be easily downloaded using `datalad get <filename>`, and files can be removed from your computer at any time using `datalad drop <filename>`. As the dataset is relatively large, this will allow you to only work with the data that you need and you can drop the rest when you are done with it.\n",
    "\n",
    "3) All of the DataLad commands can be run within Python using the datalad [python api](http://docs.datalad.org/en/latest/modref.html).\n",
    "\n",
    "We will only be covering a few basic DataLad functions to get and drop data. We encourage the interested reader to read the very comprehensive DataLad [User Handbook](http://handbook.datalad.org/en/latest/) for more details and troubleshooting.\n",
    "\n",
    "### Installing Datalad\n",
    "\n",
    "DataLad can be easily installed using [pip](https://pip.pypa.io/en/stable/).\n",
    "\n",
    "`pip install datalad`\n",
    "\n",
    "Unfortunately, it currently requires manually installing the [git-annex](https://git-annex.branchable.com/) dependency, which is not automatically installed using pip.\n",
    "\n",
    "If you are using OSX, we recommend installing git-annex using [homebrew](https://brew.sh/) package manager.\n",
    "\n",
    "`brew install git-annex`\n",
    "\n",
    "If you are on Debian/Ubuntu we recommend enabling the [NeuroDebian](http://neuro.debian.net/) repository and installing with apt-get.\n",
    "\n",
    "`sudo apt-get install datalad`\n",
    "\n",
    "For more installation options, we recommend reading the DataLad [installation instructions](https://git-annex.branchable.com/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:13:29.376447Z",
     "start_time": "2022-01-26T03:13:27.383571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datalad in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (0.15.4)\n",
      "Requirement already satisfied: tqdm in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (4.62.3)\n",
      "Requirement already satisfied: iso8601 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (0.1.16)\n",
      "Requirement already satisfied: chardet>=3.0.4 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (4.0.0)\n",
      "Requirement already satisfied: fasteners>=0.14 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (0.16.3)\n",
      "Requirement already satisfied: boto in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (2.49.0)\n",
      "Requirement already satisfied: simplejson in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (3.17.3)\n",
      "Requirement already satisfied: distro in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (1.6.0)\n",
      "Requirement already satisfied: patool>=1.7 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (1.12)\n",
      "Requirement already satisfied: requests>=1.2 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (2.26.0)\n",
      "Requirement already satisfied: wrapt in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (1.12.1)\n",
      "Requirement already satisfied: annexremote in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (1.5.0)\n",
      "Requirement already satisfied: packaging in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (21.3)\n",
      "Requirement already satisfied: keyring>=8.0 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (23.4.0)\n",
      "Requirement already satisfied: whoosh in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (2.7.4)\n",
      "Requirement already satisfied: keyrings.alt in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (4.1.0)\n",
      "Requirement already satisfied: msgpack in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (1.0.2)\n",
      "Requirement already satisfied: PyGithub in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (1.55)\n",
      "Requirement already satisfied: humanize in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (3.11.0)\n",
      "Requirement already satisfied: appdirs in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (1.4.4)\n",
      "Requirement already satisfied: python-gitlab in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from datalad) (2.10.0)\n",
      "Requirement already satisfied: six in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from fasteners>=0.14->datalad) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from keyring>=8.0->datalad) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=3.6->keyring>=8.0->datalad) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from requests>=1.2->datalad) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from requests>=1.2->datalad) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from requests>=1.2->datalad) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from requests>=1.2->datalad) (2.0.4)\n",
      "Requirement already satisfied: future in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from annexremote->datalad) (0.18.2)\n",
      "Requirement already satisfied: setuptools in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from humanize->datalad) (58.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from packaging->datalad) (3.0.4)\n",
      "Requirement already satisfied: pyjwt>=2.0 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from PyGithub->datalad) (2.1.0)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from PyGithub->datalad) (1.4.0)\n",
      "Requirement already satisfied: deprecated in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from PyGithub->datalad) (1.2.12)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from pynacl>=1.4.0->PyGithub->datalad) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub->datalad) (2.21)\n",
      "Requirement already satisfied: requests-toolbelt>=0.9.1 in /Users/lukechang/opt/anaconda3/lib/python3.8/site-packages (from python-gitlab->datalad) (0.9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datalad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data with DataLad\n",
    "\n",
    "The FNL dataset can be accessed at the following location https://openneuro.org/datasets/ds003521. To download the dataset run `datalad install https://github.com/OpenNeuroDatasets/ds003521.git` in a terminal in the location where you would like to install the dataset. Don't forget to change the directory to a folder on your local computer. The full dataset is approximately 202gb.\n",
    "\n",
    "You can run this from the notebook using the `!` cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:13:35.508636Z",
     "start_time": "2022-01-26T03:13:34.682378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukechang/Downloads/FridayNightLights\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "download_path = '/Users/lukechang/Downloads/FridayNightLights'\n",
    "\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)\n",
    "\n",
    "%cd {download_path}\n",
    "\n",
    "!datalad install https://github.com/OpenNeuroDatasets/ds003521.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalad Basics\n",
    "\n",
    "You might be surprised to find that after cloning the dataset that it barely takes up any space using `du -sh`. This is because cloning only downloads the metadata of the dataset to see what files are included.\n",
    "\n",
    "You can check to see how big the entire dataset would be if you downloaded everything using `datalad status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:13:42.292329Z",
     "start_time": "2022-01-26T03:13:40.639338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukechang/Downloads/FridayNightLights/ds003521\n",
      "1368 annex'd files (202.6 GB recorded total size)\n",
      "nothing to save, working tree clean\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd ~/Downloads/FridayNightLights/ds003521\n",
    "\n",
    "!datalad status --annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data\n",
    "One of the really nice features of datalad is that you can see all of the data without actually storing it on your computer. When you want a specific file you use `datalad get <filename>` to download that specific file. Importantly, you do not need to download all of the data at once, only when you need it.\n",
    "\n",
    "Now that we have cloned the repository we can grab individual files. For example, suppose we wanted to grab the first subject's confound regressors generated by fmriprep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:13:47.539826Z",
     "start_time": "2022-01-26T03:13:46.968595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!datalad get participants.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check and see how much of the total dataset we have downloaded using `datalad status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:13:50.103911Z",
     "start_time": "2022-01-26T03:13:48.693438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368 annex'd files (0.0 B/202.6 GB present/total size)\r\n",
      "nothing to save, working tree clean\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!datalad status --annex all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to download all of the files you can use `datalad get .`. Depending on the size of the dataset and the speed of your internet connection, this might take awhile. One really nice thing about datalad is that if your connection is interrupted you can simply run `datalad get .` again, and it will resume where it left off.\n",
    "\n",
    "You can also install the dataset and download all of the files with a single command `datalad install -g https://github.com/OpenNeuroDatasets/ds003521.git`. You may want to do this if you have a lot of storage available and a fast internet connection. For most people, we recommend only downloading the files you need for your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Data\n",
    "Most people do not have unlimited space on their hard drives and are constantly looking for ways to free up space when they are no longer actively working with files. Any file in a dataset can be removed using `datalad drop`. Importantly, this does not delete the file, but rather removes it from your computer. You will still be able to see file metadata after it has been dropped in case you want to download it again in the future.\n",
    "\n",
    "As an example, let's drop the `participants.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:14:11.398434Z",
     "start_time": "2022-01-26T03:14:10.214159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m                                                                            "
     ]
    }
   ],
   "source": [
    "!datalad drop participants.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalad has a Python API\n",
    "One particularly nice aspect of datalad is that it has a Python API, which means that anything you would like to do with datalad in the commandline, can also be run in Python. See the details of the datalad [Python API](http://docs.datalad.org/en/latest/modref.html).\n",
    "\n",
    "For example, suppose you would like to clone a data repository, such as the Localizer dataset. You can run `dl.clone(source=url, path=location)`. Make sure you set `download_path` to the location where you would like the Localizer repository installed.\n",
    "\n",
    "Also, note that datalad uses asyncio, which can lead to `RuntimeError: Cannot run the event loop while another loop is running` errors. You may run into this issue if you are running the code within a jupyter notebook. See the [datalad](https://handbook.datalad.org/en/latest/basics/101-135-help.html#asyncio-errors-at-datalad-import) documentation for more details on workarounds using `nest_asyncio`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:20:35.007489Z",
     "start_time": "2022-01-26T03:20:24.333190Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Cloning dataset to Dataset(/Users/lukechang/Downloads/FridayNightLights) \n",
      "[INFO] Attempting to clone from https://github.com/OpenNeuroDatasets/ds003521.git to /Users/lukechang/Downloads/FridayNightLights \n",
      "[INFO] Start enumerating objects \n",
      "[INFO] Start counting objects \n",
      "[INFO] Start compressing objects \n",
      "[INFO] Start receiving objects \n",
      "[INFO] Start resolving deltas \n",
      "[INFO] Completed clone attempts for Dataset(/Users/lukechang/Downloads/FridayNightLights) \n",
      "[INFO] scanning for annexed files (this may take some time) \n",
      "[INFO] Remote origin not usable by git-annex; setting annex-ignore \n",
      "[INFO] https://github.com/OpenNeuroDatasets/ds003521.git/config download failed: Not Found \n",
      "[INFO] access to 1 dataset sibling s3-PRIVATE not auto-enabled, enable with:\n",
      "| \t\tdatalad siblings -d \"/Users/lukechang/Downloads/FridayNightLights\" enable -s s3-PRIVATE \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset('/Users/lukechang/Downloads/FridayNightLights')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datalad.api as dl\n",
    "import pandas as pd\n",
    "\n",
    "download_path = '/Users/lukechang/Downloads/FridayNightLights'\n",
    "\n",
    "dl.clone(source='https://github.com/OpenNeuroDatasets/ds003521.git', path=download_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a dataset instance using `dl.Dataset(path_to_data)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:21:12.855725Z",
     "start_time": "2022-01-26T03:21:12.848555Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = dl.Dataset(download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of the dataset have we downloaded?  We can check the status of the annex using `ds.status(annex='all')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:21:16.781418Z",
     "start_time": "2022-01-26T03:21:15.478924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368 annex'd files (0.0 B/202.6 GB present/total size)\n",
      "nothing to save, working tree clean\n"
     ]
    }
   ],
   "source": [
    "results = ds.status(annex='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's empty, which makes sense since we only cloned the dataset. \n",
    "\n",
    "Now we need to get some data. Let's start with something small to play with first.\n",
    "\n",
    "Let's use `glob` to find all of the tab-delimited confound data generated by fmriprep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:21:23.316842Z",
     "start_time": "2022-01-26T03:21:23.296824Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000216/func/sub-sid000216_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000217/func/sub-sid000217_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000375/func/sub-sid000375_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000475/func/sub-sid000475_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000476/func/sub-sid000476_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000494/func/sub-sid000494_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000496/func/sub-sid000496_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000498/func/sub-sid000498_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000529/func/sub-sid000529_task-movie_run-1_desc-confounds_timeseries.tsv',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/fmriprep/sub-sid000570/func/sub-sid000570_task-movie_run-1_desc-confounds_timeseries.tsv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(download_path, 'derivatives', 'fmriprep', '*', 'func', '*tsv'))\n",
    "file_list.sort()\n",
    "file_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glob can search the filetree and see all of the relevant data even though none of it has been downloaded yet.\n",
    "\n",
    "Let's now download the first subjects confound regressor file and load it using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:21:30.300047Z",
     "start_time": "2022-01-26T03:21:29.984133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_signal</th>\n",
       "      <th>global_signal_derivative1</th>\n",
       "      <th>global_signal_power2</th>\n",
       "      <th>global_signal_derivative1_power2</th>\n",
       "      <th>csf</th>\n",
       "      <th>csf_derivative1</th>\n",
       "      <th>csf_power2</th>\n",
       "      <th>csf_derivative1_power2</th>\n",
       "      <th>white_matter</th>\n",
       "      <th>white_matter_derivative1</th>\n",
       "      <th>...</th>\n",
       "      <th>motion_outlier25</th>\n",
       "      <th>motion_outlier26</th>\n",
       "      <th>motion_outlier27</th>\n",
       "      <th>motion_outlier28</th>\n",
       "      <th>motion_outlier29</th>\n",
       "      <th>motion_outlier30</th>\n",
       "      <th>motion_outlier31</th>\n",
       "      <th>motion_outlier32</th>\n",
       "      <th>motion_outlier33</th>\n",
       "      <th>motion_outlier34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>449.788009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309.252709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609.594384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371605.312452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>451.645901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>448.416865</td>\n",
       "      <td>-1.371143</td>\n",
       "      <td>201077.685202</td>\n",
       "      <td>1.880034</td>\n",
       "      <td>600.366320</td>\n",
       "      <td>-9.228063</td>\n",
       "      <td>360439.718706</td>\n",
       "      <td>85.157149</td>\n",
       "      <td>451.395569</td>\n",
       "      <td>-0.250332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447.555550</td>\n",
       "      <td>-0.861315</td>\n",
       "      <td>200305.970725</td>\n",
       "      <td>0.741864</td>\n",
       "      <td>597.729338</td>\n",
       "      <td>-2.636982</td>\n",
       "      <td>357280.362098</td>\n",
       "      <td>6.953674</td>\n",
       "      <td>450.599238</td>\n",
       "      <td>-0.796331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447.312503</td>\n",
       "      <td>-0.243048</td>\n",
       "      <td>200088.475226</td>\n",
       "      <td>0.059072</td>\n",
       "      <td>596.315244</td>\n",
       "      <td>-1.414094</td>\n",
       "      <td>355591.870663</td>\n",
       "      <td>1.999662</td>\n",
       "      <td>450.606712</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>446.627385</td>\n",
       "      <td>-0.685118</td>\n",
       "      <td>199476.020980</td>\n",
       "      <td>0.469387</td>\n",
       "      <td>596.015874</td>\n",
       "      <td>-0.299371</td>\n",
       "      <td>355234.921789</td>\n",
       "      <td>0.089623</td>\n",
       "      <td>450.673392</td>\n",
       "      <td>0.066680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_signal  global_signal_derivative1  global_signal_power2  \\\n",
       "0     449.788009                        NaN         202309.252709   \n",
       "1     448.416865                  -1.371143         201077.685202   \n",
       "2     447.555550                  -0.861315         200305.970725   \n",
       "3     447.312503                  -0.243048         200088.475226   \n",
       "4     446.627385                  -0.685118         199476.020980   \n",
       "\n",
       "   global_signal_derivative1_power2         csf  csf_derivative1  \\\n",
       "0                               NaN  609.594384              NaN   \n",
       "1                          1.880034  600.366320        -9.228063   \n",
       "2                          0.741864  597.729338        -2.636982   \n",
       "3                          0.059072  596.315244        -1.414094   \n",
       "4                          0.469387  596.015874        -0.299371   \n",
       "\n",
       "      csf_power2  csf_derivative1_power2  white_matter  \\\n",
       "0  371605.312452                     NaN    451.645901   \n",
       "1  360439.718706               85.157149    451.395569   \n",
       "2  357280.362098                6.953674    450.599238   \n",
       "3  355591.870663                1.999662    450.606712   \n",
       "4  355234.921789                0.089623    450.673392   \n",
       "\n",
       "   white_matter_derivative1  ...  motion_outlier25  motion_outlier26  \\\n",
       "0                       NaN  ...               0.0               0.0   \n",
       "1                 -0.250332  ...               0.0               0.0   \n",
       "2                 -0.796331  ...               0.0               0.0   \n",
       "3                  0.007475  ...               0.0               0.0   \n",
       "4                  0.066680  ...               0.0               0.0   \n",
       "\n",
       "   motion_outlier27  motion_outlier28  motion_outlier29  motion_outlier30  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   motion_outlier31  motion_outlier32  motion_outlier33  motion_outlier34  \n",
       "0               0.0               0.0               0.0               0.0  \n",
       "1               0.0               0.0               0.0               0.0  \n",
       "2               0.0               0.0               0.0               0.0  \n",
       "3               0.0               0.0               0.0               0.0  \n",
       "4               0.0               0.0               0.0               0.0  \n",
       "\n",
       "[5 rows x 585 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ds.get(file_list[0])\n",
    "\n",
    "confounds = pd.read_csv(file_list[0], sep='\\t')\n",
    "confounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to drop that file? Just like the CLI, we can use `ds.drop(file_name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:21:40.635072Z",
     "start_time": "2022-01-26T03:21:40.136097Z"
    }
   },
   "outputs": [],
   "source": [
    "result = ds.drop(file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that it is actually removed, let's try to load it again with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:21:43.118160Z",
     "start_time": "2022-01-26T03:21:42.957671Z"
    }
   },
   "outputs": [],
   "source": [
    "confounds = pd.read_csv(file_list[0], sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it was successfully removed.\n",
    "\n",
    "We can also load the entire dataset in one command if want using `ds.get(dataset='.', recursive=True)`. We are not going to do it right now as this will take awhile and require lots of free hard disk space.\n",
    "\n",
    "Let's actually download one of the files we will be using in the tutorial. First, let's use glob to get a list of all of the functional data that has been preprocessed by fmriprep, denoised, and smoothed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:25:12.731742Z",
     "start_time": "2022-01-26T03:25:12.712913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000216_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000217_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000375_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000475_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000476_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000494_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000498_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000529_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000570_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000573_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000667_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000668_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000669_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000671_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000677_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000678_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000679_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000680_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000681_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000682_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000683_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000688_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000692_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000694_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000695_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000697_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000698_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000699_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000704_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000705_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000706_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000707_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000708_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000710_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(download_path, 'derivatives', 'denoised', 'smoothed', '*_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.hdf5'))\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:26:16.685388Z",
     "start_time": "2022-01-26T03:26:16.667112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000216_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000217_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000375_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000475_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000476_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000494_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000498_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000529_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000570_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000573_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000667_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000668_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000669_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000671_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000677_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000678_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000679_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000680_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000681_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000682_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000683_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000688_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000692_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000694_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000695_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000697_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000698_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000699_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000704_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000705_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000706_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000707_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000708_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000710_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(download_path, 'derivatives', 'denoised', 'smoothed', '*_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz'))\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the first subject's file using `ds.get()`. This file is 825mb, so this might take a few minutes depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:27:49.985316Z",
     "start_time": "2022-01-26T03:27:44.674811Z"
    }
   },
   "outputs": [
    {
     "ename": "IncompleteResultsError",
     "evalue": "Command did not complete successfully. 1 failed:\n[{'action': 'get',\n  'annexkey': 'MD5E-s1260187407--696e2e23879c4093d30cf3776f614bc0.nii.gz',\n  'error_message': 'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden',\n  'path': '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000216_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n  'refds': '/Users/lukechang/Downloads/FridayNightLights',\n  'status': 'error',\n  'type': 'file'}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteResultsError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lt/52_7v4r10qg8m6_2fjzqh1z80000gn/T/ipykernel_613/4243294396.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datalad/distribution/dataset.py\u001b[0m in \u001b[0;36mapply_func\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mds_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morig_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datalad/interface/utils.py\u001b[0m in \u001b[0;36meval_func\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mlgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Returning return_func from eval_func for %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datalad/interface/utils.py\u001b[0m in \u001b[0;36mreturn_func\u001b[0;34m(wrapped_, instance_, args_, kwargs_)\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0;31m# unwind generator if there is one, this actually runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                     \u001b[0;31m# any processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'item-or-list'\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datalad/interface/utils.py\u001b[0m in \u001b[0;36mgenerator_func\u001b[0;34m(*_args, **_kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincomplete_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                 raise IncompleteResultsError(\n\u001b[0m\u001b[1;32m    462\u001b[0m                     \u001b[0mfailed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincomplete_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                     msg=\"Command did not complete successfully\")\n",
      "\u001b[0;31mIncompleteResultsError\u001b[0m: Command did not complete successfully. 1 failed:\n[{'action': 'get',\n  'annexkey': 'MD5E-s1260187407--696e2e23879c4093d30cf3776f614bc0.nii.gz',\n  'error_message': 'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden\\n'\n                   'download failed: Forbidden',\n  'path': '/Users/lukechang/Downloads/FridayNightLights/derivatives/denoised/smoothed/sub-sid000216_task-movie_run-1_space-MNI152NLin2009cAsym_desc-preproc_trim_smooth6_denoised_bold.nii.gz',\n  'refds': '/Users/lukechang/Downloads/FridayNightLights',\n  'status': 'error',\n  'type': 'file'}]"
     ]
    }
   ],
   "source": [
    "result = ds.get(file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of the dataset have we downloaded?  We can check the status of the annex using `ds.status(annex='all')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T03:40:53.972952Z",
     "start_time": "2022-01-26T03:40:52.447388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untracked: .DS_Store (file)\n",
      "1368 annex'd files (0.0 B/202.6 GB present/total size)\n"
     ]
    }
   ],
   "source": [
    "result = ds.status(annex='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07cfb842b9455a73d55ec9d38bab5362c3fe321b0e1c3eca7f51b6b16c31b8ca"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
